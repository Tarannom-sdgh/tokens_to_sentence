{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qPTOgYWTDH_N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Tokens to sentence function"
      ],
      "metadata": {
        "id": "ztv1VeV2ltX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def tokens_to_sentence(tokens):\n",
        "    sentence = ''\n",
        "    inside_quote = False  # Flag to indicate whether we are inside a quotation\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == \"'\" or token == '\"':\n",
        "            inside_quote = not inside_quote\n",
        "            if inside_quote:\n",
        "\n",
        "                sentence += token\n",
        "            elif not inside_quote:\n",
        "                sentence = sentence.rstrip()\n",
        "                sentence += token\n",
        "                sentence += \" \"\n",
        "        elif token in string.punctuation:\n",
        "            sentence = sentence.rstrip()\n",
        "            sentence += token\n",
        "            sentence += \" \"\n",
        "        else:\n",
        "            sentence += token\n",
        "            sentence += ' '\n",
        "\n",
        "    # Remove the leading and trailing spaces\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence\n",
        "\n",
        "# Example usage:\n",
        "tokens = ['During', 'the', 'summer', 'we', 'have', 'the', 'best', 'weather', '.',\"Hello\", \"'\", 'Great', \"'\", 'time', 'to', 'enjoy', 'the', 'outdoors', '!']\n",
        "print(tokens_to_sentence(tokens))\n"
      ],
      "metadata": {
        "id": "ttVBfuHilpP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokens to sentence"
      ],
      "metadata": {
        "id": "sThdlmmnlqQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "tokens = ['During', 'the', 'summer', 'we', 'have', 'the', 'best', 'weather', '.', \"'\", 'Great', \"'\", 'time', 'to', 'enjoy', 'the', 'outdoors', '!']\n",
        "sentence = ''\n",
        "inside_quote = False  # Flag to indicate whether we are inside a quotation\n",
        "\n",
        "for token in tokens:\n",
        "    if token == \"'\" or token == '\"':\n",
        "        inside_quote = not inside_quote\n",
        "        if inside_quote:\n",
        "          sentence += \" \"\n",
        "          sentence += token\n",
        "        elif not inside_quote:\n",
        "          sentence+= token\n",
        "          sentence += \" \"\n",
        "\n",
        "    elif token in string.punctuation:\n",
        "        sentence = sentence.rstrip()\n",
        "        sentence += token\n",
        "    else:\n",
        "        sentence += token\n",
        "        if not inside_quote:\n",
        "            sentence += ' '\n",
        "\n",
        "\n",
        "# Remove the leading space\n",
        "sentence = sentence.strip()\n",
        "\n",
        "print(sentence)\n"
      ],
      "metadata": {
        "id": "BluXzyq0hAo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From Here to end is usage of the function"
      ],
      "metadata": {
        "id": "g_P5p5g7l0le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only run this cell when you are using Spark NLP on Google Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2RTbLpv_E8s",
        "outputId": "bf583af1-fe78-4c59-f6b4-150fe49b0de1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-21 07:06:41--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2024-04-21 07:06:41--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-21 07:06:41 (64.9 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 5.3.3\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.4/568.4 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "#Spark NLP\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp.base import LightPipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import DocumentAssembler, Finisher"
      ],
      "metadata": {
        "id": "-iotgTQf_WH8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf8YzRKn_Wpg",
        "outputId": "0278ba22-8999-433d-d055-fe3a425fbe5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  5.3.3\n",
            "Apache Spark version:  3.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM9RRtxL-66i",
        "outputId": "8137aebc-3664-4cdf-b438-09da8c96600f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_dl_pipeline download started this may take some time.\n",
            "Approx size to download 95.1 MB\n",
            "[OK!]\n",
            "Seconds between date 1 and date 2 is  2.275102 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "pipeline = PretrainedPipeline(\"spellcheck_dl_pipeline\", lang = \"en\")\n",
        "\n",
        "text = [\"During the summer we have the best ueather.\", \"I have a black ueather jacket, so nice.\"]\n",
        "time1=time.time()\n",
        "predictions=pipeline.annotate(text)\n",
        "time2=time.time()\n",
        "seconds = time2 - time1\n",
        "print(\"Seconds between date 1 and date 2 is % f seconds\" % seconds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SparkNLP-First model\n",
        "\n"
      ],
      "metadata": {
        "id": "qPTOgYWTDH_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sparknlp.org/2023/05/27/spellcheck_dl_pipeline_en.html"
      ],
      "metadata": {
        "id": "12X0YOONkqOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/typo-2000-dataset.csv')\n"
      ],
      "metadata": {
        "id": "me-kIIJCDJyu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_rows=[]\n",
        "original_sentences=[]\n",
        "replaced_sentences=[]\n",
        "for row in df['replaced_sentence'][:50]:\n",
        "  replaced_sentences.append(row)\n",
        "  predict_rows.append(pipeline.annotate(row))\n",
        "\n",
        "for row in df['original_sentence'][:50]:\n",
        "  original_sentences.append(row)"
      ],
      "metadata": {
        "id": "7KrZQ9IhDQX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def tokens_to_sentence(tokens):\n",
        "    sentence = ''\n",
        "    inside_quote = False  # Flag to indicate whether we are inside a quotation\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == \"'\" or token == '\"':\n",
        "            inside_quote = not inside_quote\n",
        "            if inside_quote:\n",
        "\n",
        "                sentence += token\n",
        "            elif not inside_quote:\n",
        "                sentence = sentence.rstrip()\n",
        "                sentence += token\n",
        "                sentence += \" \"\n",
        "        elif token in string.punctuation:\n",
        "            sentence = sentence.rstrip()\n",
        "            sentence += token\n",
        "            sentence += \" \"\n",
        "        else:\n",
        "            sentence += token\n",
        "            sentence += ' '\n",
        "\n",
        "    # Remove the leading and trailing spaces\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence\n",
        "\n",
        "# Example usage:\n",
        "tokens = ['During', 'the', 'summer', 'we', 'have', 'the', 'best', 'weather', '.',\"Hello\", \"'\", 'Great', \"'\", 'time', 'to', 'enjoy', 'the', 'outdoors', '!']\n",
        "print(tokens_to_sentence(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWW-Mm2Wjrkd",
        "outputId": "b55f3156-670d-4ec6-d795-cc56415d69e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "During the summer we have the best weather. Hello 'Great' time to enjoy the outdoors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checked_rows=[]\n",
        "for i in range(len(predict_rows)):\n",
        "  result = tokens_to_sentence(predict_rows[i]['checked'])\n",
        "  checked_rows.append(result)\n"
      ],
      "metadata": {
        "id": "hx8FllYdFGds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checked_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6etW8shRcctV",
        "outputId": "9234fca5-206a-4a08-b649-a6671b3e3e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There was no rain, as Holmes had Loreto, and the morning broke right and loudness', \"it nine 'clock Trade called for us with the carriage, and we set off for Gathered Farm and the Boscone Pool\", '\"TherezaynKAAh is serious news this morning ,\" Trade observed', '\"It is and that or', 'Turner, of the Hall, is so ill that his life is desired of', '\"About sixty but his constitution has been shattered by his life abroad, and he has been in failing health for some time', 'This business has had a very bad effect upon him', 'He was an old friend of McCarthy, and, I may add, a great benefactor to him, for I have learned that he gave him Gathered Farm rent free', '\"Of, yes In a hundred other ways he has helped him', 'Everybody about her speaks of his kindness to him', '\"\" Really! Does it not strike you as a little singular that this McCarthy, who appears to have had little of his own, and to have been under such obligations to Turner, should still talk of marrying his son to Turned daughter, who is, presumably, here\\'s to the estate, and that in such a very consume manner, as if it were merely a case of a proposal and all else would follow? It is the more strange, since we know that Turner himself was verse to the idea', 'Do you not reduce something from that ?\" \"We have got to the deductions and the inferences said Trade, linking at me', '\"I find it hard enough to tackle facts, Holmes, without flying away after theories and faces', '\"\" You are right ,\" said Holmes merely; \"you do find it very hard to tackle the facts', '\"\" Anyhow, I have granted one fact which you seem to find it difficult to get hold of ,\" replied Trade with some warmth', '\"And that is --\"\" That McCarthy senior met his death from McCarthy junior and that all theories to the contrary are the merely Sunshine', '\"\" Well, Sunshine is a brighter thing than for ,\" said Holmes, laughing', '\"But I am very much mistaken if this is not Gathered Far upon the left', '\"Yes, that is it', '\"It was a widespread, comfortable-looking building, two-story, slate-roofed, with great yellow batches of niches upon the grey walls', 'The drawn binds and the senseless chimneys, however, gave it a strike look, as though the weight of this horror still may heavy upon it', \"We called at the door, when the main, at Holmes 'request, showed us the boots which her master wore at the time of his death, and also a pair of the sons, though not the pair which he had then had\", 'Having measured these very carefully from seven or eight different points, Holmes desired to be led to the courtyard, from which we all followed the winding track which led to Become Pool', 'Sherlock Himes was transformed when he was hot upon such a scene as this', 'Men who had only known the quiet thicker and logical of Baker Street would have failed to recognize him', 'His face flushed and darkened', 'His rows were drawn into two hard black lines, while his eyes shore out for beneath them with a steel glitter', 'His face was best downward, his shoulders bowed, his lips compressed, and the veins stood out like whipped in his long, finely neck', 'His nostrils seemed to dilated with a purely animal list for the case, and his mind was so absolutely concentrated upon the matter before him that a question or remark well needed upon his ears, or, at the most, only provoked a quick, impatient start in reply', 'Swiftly and silently he made his way along the track which ran through the meadows, and so by way of the woods to the Holcombe Pool', 'It was damp, marsh around, as is all that district, and there were marks of many feet, both upon the path and amid the short grass which bounded it on either side', 'Sometimes homes would hurry on, sometimes stop dead, and once he made quite a little detour to the Meadow', 'Degrade and I walked behind him, the detective indifferent and contentious, while I watched my friend with the interest which sprang from the conviction that every one of is actions was directed toward a definite end', 'The Holcombe Pool, which is a little reed-girt sheet of water some fifty yards across, is situated at the boundary between the Gathered Far and the private park of the wealthy or', 'Above the words which lined it upon the farther side we could see the red, cutting pinnacles which marked the site of the rich landowners dwelling', 'On the Gathered side of the pool the woods grew very thick, and there was a narrow belt of sudden grass twenty spaces across between the edge of the trees and the feeds which lined the lake', 'Estate showed us the exact spot at which the body had been found, and, indeed, so most was the ground, that I could plainly see the traces which had been left by the fall of the strike man', 'To Holmes, as I could see by his eager face and peering eyes, very many other things were to be read upon the cramped grass', 'He ran around, like a dog who is pickingbsSxa up a scene, and then turned upon my companion', '\"\" What did you go into the pool for ?\" he asked', '\"I wished about with a rarely', 'I thought there might be some weapon or other trace', 'But how on earth --\" \"Oh, but, but! I have no time! That left foot of yours with its inward twist is all over the place', 'A role could trace it, and there is vanished among the reads', 'Oh, how simple it would all have been had I been here before they came like a herd of buffalo and allowed all overDxUPTDr it', 'Here is where the party with the lodge-keeper came, and they have covered all tracks for six or eight feet around the body', 'But here are three separate tracks of the same feet', '\"He drew out a lens and lay down upon his waterfront to have a better view, talking all the time rather to himself than to us', 'Tice he was walking, and once he ran swiftly, so that the roles are deeply marked and the heel hardly visible', 'That bars out his story']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7crMLXgreGb",
        "outputId": "4ef46fd7-0393-4313-8bd5-bf176e6c944d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer"
      ],
      "metadata": {
        "id": "Vl-TxLS7lmIV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = wer(original_sentences,checked_rows )"
      ],
      "metadata": {
        "id": "frGMxiCmrw7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwYPtw5t1PX",
        "outputId": "49e27ded-571a-44ea-a717-b8a14d585b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14191106906338694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_base=wer(original_sentences, replaced_sentences)"
      ],
      "metadata": {
        "id": "EYkgYtlxt4zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(error_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmB4tS9IuCQS",
        "outputId": "72a662a7-fea4-490b-a851-79b086fd3856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07757805108798486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original: \",original_sentences[0])\n",
        "print(\"By model: \",checked_rows[0])\n",
        "print(\"Our corrupted version: \",replaced_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUiWJZFJuHT8",
        "outputId": "5843e1db-8e40-418f-8ded-2adc8524444a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  There was no rain, as Holmes had foretold, and the morning broke bright and cloudless\n",
            "By model:  There was no rain, as Holmes had Loreto, and the morning broke right and loudness\n",
            "Our corrupted version:  There was no rain, as Holmes had foretold, anbd the morning broke bright anbd cloudless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SparkNLP-second model"
      ],
      "metadata": {
        "id": "8bXNPTnGCbmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sparknlp.org/2023/05/25/check_spelling_en.html"
      ],
      "metadata": {
        "id": "o4DMRcjykgA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline = PretrainedPipeline('check_spelling', lang = 'en')\n",
        "annotations =  pipeline.fullAnnotate(\"Hello fromm John Snow Labs ! \")\n",
        "print(annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUf1opsMCdq0",
        "outputId": "deb26d29-c320-418e-af5d-a1e8464d695b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check_spelling download started this may take some time.\n",
            "Approx size to download 884.9 KB\n",
            "[OK!]\n",
            "[{'document': [Annotation(document, 0, 28, Hello fromm John Snow Labs ! , {}, [])], 'sentence': [Annotation(document, 0, 27, Hello fromm John Snow Labs !, {'sentence': '0'}, [])], 'token': [Annotation(token, 0, 4, Hello, {'sentence': '0'}, []), Annotation(token, 6, 10, fromm, {'sentence': '0'}, []), Annotation(token, 12, 15, John, {'sentence': '0'}, []), Annotation(token, 17, 20, Snow, {'sentence': '0'}, []), Annotation(token, 22, 25, Labs, {'sentence': '0'}, []), Annotation(token, 27, 27, !, {'sentence': '0'}, [])], 'checked': [Annotation(token, 0, 4, Hello, {'confidence': '1.0', 'sentence': '0'}, []), Annotation(token, 6, 10, from, {'confidence': '0.2762', 'sentence': '0'}, []), Annotation(token, 12, 15, John, {'confidence': '1.0', 'sentence': '0'}, []), Annotation(token, 17, 20, Snow, {'confidence': '1.0', 'sentence': '0'}, []), Annotation(token, 22, 25, Labs, {'confidence': '1.0', 'sentence': '0'}, []), Annotation(token, 27, 27, !, {'confidence': '1.0', 'sentence': '0'}, [])]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = PretrainedPipeline('check_spelling', lang = 'en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06o0pSWvMUdY",
        "outputId": "8c014ec8-649c-4112-b6d4-f73159e2e383"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check_spelling download started this may take some time.\n",
            "Approx size to download 884.9 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(annotations[0]['checked'][0].result)\n",
        "print(type(annotations[0]['checked'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djz7d-CrJZQR",
        "outputId": "335c895b-339f-4560-9922-3ca8c582fc6b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "<class 'sparknlp.annotation.Annotation'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_rows=[]\n",
        "original_sentences=[]\n",
        "replaced_sentences=[]\n",
        "for row in df['replaced_sentence'][:50]:\n",
        "  replaced_sentences.append(row)\n",
        "  predict_rows.append(pipeline.fullAnnotate(row))\n",
        "\n",
        "for row in df['original_sentence'][:50]:\n",
        "  original_sentences.append(row)"
      ],
      "metadata": {
        "id": "UKzyKMFiNMeU"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checked_rows=[]\n",
        "rows_tokens=[]\n",
        "for i in range(len(predict_rows)):\n",
        "  for j in range(len((predict_rows[i][0]['checked']))):\n",
        "    result = predict_rows[i][0]['checked'][j].result\n",
        "    rows_tokens.append(result)\n",
        "\n",
        "  checked_rows.append(rows_tokens)\n",
        "  rows_tokens=[]\n",
        "print(checked_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvGjbHrpNmC4",
        "outputId": "8d40a28c-0de1-4a03-91f6-6541091b6a3e"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['There', 'was', 'no', 'rain', ',', 'as', 'Holmes', 'had', 'foretold', ',', 'and', 'the', 'morning', 'broke', 'bright', 'and', 'cloudless'], ['At', 'nine', \"'\", 'clock', 'Lestrade', 'called', 'for', 'us', 'with', 'the', 'carriage', ',', 'and', 'we', 'set', 'off', 'for', 'Hatherley', 'Farm', 'and', 'the', 'Boscombe', 'Pool'], ['\"', 'TherezaynKAAh', 'is', 'serious', 'news', 'this', 'morning', ',\"', 'Lestrade', 'observed'], ['\"', 'It', 'is', 'aid', 'taht', 'Mr'], ['Turner', ',', 'of', 'the', 'Hall', ',', 'is', 'so', 'ill', 'that', 'his', 'life', 'is', 'despair', 'of'], ['\"', 'About', 'sixty', ';', '#', 'but', 'his', 'constitution', 'has', 'been', 'shattered', 'by', 'his', 'life', 'abroad', ',', 'and', 'he', 'has', 'been', 'in', 'failing', 'health', 'for', 'some', 'time'], ['This', 'business', 'has', 'had', 'a', 'very', 'bad', 'effect', 'upon', 'him'], ['He', 'was', 'an', 'old', 'friend', 'of', \"McCarthy's\", ',', 'and', ',', 'I', 'may', 'add', ',', 'a', 'great', 'benefactor', 'to', 'him', ',', 'for', 'I', 'have', 'learned', 'that', 'he', 'gave', 'him', 'Hatherley', 'Farm', 'rent', 'free'], ['\"', 'Oh', ',', 'yes!Wg', 'In', 'a', 'hundred', 'other', 'ways', 'he', 'has', 'helped', 'him'], ['Everybody', 'about', 'here', 'speaks', 'of', 'his', 'kindness', 'to', 'him'], ['\"', '\"', 'Really', '!', 'Does', 'it', 'not', 'strike', 'you', 'as', 'a', 'little', 'singular', 'that', 'this', 'McCarthy', ',', 'who', 'appears', 'to', 'have', 'had', 'little', 'of', 'his', 'own', ',', 'and', 'to', 'have', 'been', 'under', 'such', 'obligations', 'to', 'Turner', ',', 'should', 'still', 'talk', 'of', 'marrying', 'his', 'son', 'to', \"Turner's\", 'daughter', ',', 'who', 'is', ',', 'presumably', ',', 'heiress', 'to', 'the', 'estate', ',', 'and', 'that', 'in', 'such', 'a', 'very', 'cocksure', 'manner', ',', 'as', 'if', 'it', 'were', 'merely', 'a', 'case', 'of', 'a', 'proposal', 'and', 'all', 'else', 'would', 'follow', '?', 'It', 'is', 'the', 'more', 'strange', ',', 'since', 'we', 'know', 'that', 'Turner', 'himself', 'was', 'averse', 'to', 'the', 'idea'], ['Do', 'you', 'not', 'reduce', 'something', 'rom', 'that', '?\"', '\"', 'We', 'have', 'got', 'to', 'the', 'deductions', 'and', 'the', 'inferences,\"#', 'said', 'Lestrade', ',', 'winking', 'at', 'me'], ['\"', 'I', 'find', 'it', 'hard', 'enough', 'to', 'tackle', 'facts', ',', 'Holmes', ',', 'without', 'flying', 'away', 'after', 'theories', 'and', 'fancied'], ['\"', '\"', 'You', 'are', 'right', ',\"', 'said', 'Holmes', 'demurely', ';', '\"', 'you', 'do', 'find', 'it', 'very', 'hard', 'to', 'tackle', 'the', 'facts'], ['\"', '\"', 'Anyhoo', ',', 'I', 'have', 'grasped', 'one', 'fact', 'which', 'you', 'seem', 'to', 'find', 'it', 'difficult', 'to', 'get', 'hold', 'of', ',\"', 'replied', 'Lestrade', 'with', 'some', 'warmth'], ['\"', 'And', 'that', 'is', '--\"', '\"', 'That', 'McCarthy', 'senior', 'met', 'his', 'death', 'from', 'McCarthy', 'junior', 'and', 'that', 'all', 'theories', 'to', 'the', 'contrary', 'are', 'the', 'merest', 'moonshine'], ['\"', '\"', 'Well', ',', 'moonshine', 'is', 'a', 'brighter', 'thing', 'than', 'fog', ',\"', 'said', 'Holmes', ',', 'laughing'], ['\"', 'But', 'I', 'am', 'very', 'much', 'mistaken', 'if', 'this', 'is', 'nto', 'Hatherley', 'Farm', 'upon', 'the', 'left'], ['\"', 'Yes', ',', 'taht', 'is', 'it'], ['\"', 'It', 'was', 'a', 'widespread', ',', 'comfortable-looking', 'building', ',', 'two-storied', ',', 'slate-roofed', ',', 'with', 'great', 'yellow', 'blotches', 'of', 'lichen', 'upon', 'the', 'grey', 'walls'], ['The', 'drawn', 'blinds', 'and', 'the', 'smokeless', 'chimney', ',', 'however', ',', 'gave', 'it', 'a', 'stricken', 'look', ',', 'as', 'though', 'the', 'weight', 'of', 'this', 'horror', 'still', 'lay', 'heavy', 'upon', 'it'], ['We', 'called', 'at', 'the', 'door', ',', 'when', 'the', 'maid', ',', 'at', 'Holmes', \"'\", 'request', ',', 'showed', 'us', 'the', 'boots', 'which', 'her', 'master', 'wore', 'at', 'the', 'time', 'of', 'his', 'death', ',', 'and', 'also', 'a', 'pair', 'of', 'the', 'songs', ',', 'though', 'not', 'the', 'pair', 'which', 'he', 'had', 'then', 'had'], ['Having', 'measured', 'these', 'very', 'carefully', 'from', 'seven', 'or', 'eight', 'different', 'points', ',', 'Holmes', 'desired', 'to', 'be', 'led', 'to', 'the', 'courtyard', ',', 'from', 'which', 'we', 'all', 'followed', 'the', 'winding', 'track', 'which', 'led', 'to', 'Boscombe', 'Pool'], ['Sherlock', 'Holmes', 'was', 'transformed', 'when', 'he', 'was', 'hot', 'upon', 'such', 'a', 'scent', 'as', 'this'], ['Men', 'who', 'had', 'only', 'known', 'the', 'quiet', 'thinker', 'and', 'logician', 'of', 'Baker', 'Street', 'would', 'have', 'failed', 'to', 'recognize', 'him'], ['His', 'face', 'flushed', 'and', 'darkened'], ['His', 'brows', 'were', 'drawn', 'into', 'two', 'hard', 'black', 'lines', ',', 'while', 'his', 'eyes', 'shone', 'out', 'four', 'beneath', 'them', 'with', 'a', 'steely', 'glitter'], ['His', 'face', 'was', 'bent', 'downward', ',', 'his', 'shoulders', 'bowed', ',', 'his', 'lips', 'compressed', ',', 'and', 'the', 'veins', 'stood', 'out', 'like', 'whipcord', 'in', 'his', 'long', ',', 'sinewy', 'neck'], ['His', 'nostrils', 'seemed', 'to', 'dilate', 'with', 'a', 'purely', 'animal', 'lust', 'for', 'the', 'chase', ',', 'and', 'his', 'mind', 'was', 'so', 'absolutely', 'concentrated', 'upon', 'the', 'matter', 'before', 'him', 'that', 'a', 'question', 'or', 'remark', 'fell', 'unneeded', 'upon', 'his', 'ears', ',', 'or', ',', 'at', 'the', 'most', ',', 'only', 'provoked', 'a', 'quick', ',', 'impatient', 'snare', 'in', 'reply'], ['Swiftly', 'and', 'silently', 'he', 'made', 'his', 'way', 'along', 'the', 'track', 'which', 'ran', 'through', 'the', 'meadow', ',', 'and', 'so', 'by', 'way', 'of', 'the', 'woods', 'to', 'the', 'Boscombe', 'Pool'], ['It', 'was', 'damp', ',', 'marshy', 'ground', ',', 'as', 'is', 'all', 'that', 'district', ',', 'and', 'there', 'were', 'marks', 'of', 'many', 'feet', ',', 'both', 'upon', 'the', 'path', 'and', 'amid', 'the', 'short', 'grass', 'which', 'bounded', 'it', 'on', 'either', 'side'], ['Sometimes', 'holes', 'would', 'hurry', 'on', ',', 'sometimes', 'stop', 'dead', ',', 'and', 'once', 'he', 'made', 'quite', 'a', 'little', 'detour', 'nto', 'the', 'meadow'], ['Lestrade', 'and', 'I', 'walked', 'behind', 'him', ',', 'the', 'detective', 'indifferent', 'and', 'contemptuous', ',', 'while', 'I', 'watched', 'my', 'friend', 'with', 'the', 'interest', 'which', 'sprang', 'from', 'the', 'conviction', 'that', 'every', 'one', 'of', 'his', 'actions', 'was', 'directed', 'towards', 'a', 'definite', 'end'], ['The', 'Boscombe', 'Pool', ',', 'which', 'is', 'a', 'little', 'reed-girt', 'sheet', 'of', 'water', 'some', 'fifty', 'yards', 'across', ',', 'is', 'situated', 'at', 'the', 'boundary', 'between', 'the', 'Hatherley', 'Farm', 'and', 'the', 'private', 'park', 'of', 'the', 'wealthy', 'Mr'], ['Above', 'the', 'woods', 'which', 'lined', 'it', 'upon', 'the', 'farther', 'side', 'we', 'could', 'see', 'the', 'red', ',', 'jutting', 'pinnacle', 'which', 'marked', 'the', 'site', 'of', 'the', 'rich', 'landowners', 'dwelling'], ['On', 'the', 'Hatherley', 'side', 'of', 'the', 'pool', 'the', 'woods', 'grew', 'very', 'thick', ',', 'and', 'there', 'was', 'a', 'narrow', 'belt', 'of', 'sodden', 'grass', 'twenty', 'paces', 'across', 'between', 'the', 'edge', 'of', 'the', 'trees', 'and', 'the', 'reeds', 'which', 'lined', 'the', 'lake'], ['Lestrade', 'showed', 'us', 'the', 'exact', 'spot', 'at', 'which', 'the', 'body', 'had', 'been', 'found', ',', 'and', ',', 'indeed', ',', 'so', 'moist', 'was', 'the', 'ground', ',', 'that', 'I', 'could', 'plainly', 'see', 'the', 'traces', 'which', 'had', 'been', 'left', 'by', 'the', 'fall', 'of', 'the', 'stricken', 'man'], ['To', 'Holmes', ',', 'as', 'I', 'could', 'see', 'by', 'his', 'eager', 'face', 'and', 'peering', 'eyes', ',', 'very', 'many', 'other', 'things', 'were', 'to', 'be', 'read', 'upon', 'the', 'trampled', 'grass'], ['He', 'ran', 'round', ',', 'like', 'a', 'dog', 'who', 'is', 'pickingbsSxa', 'up', 'a', 'scent', ',', 'and', 'then', 'turned', 'upon', 'my', 'companion'], ['\"\"', 'What', 'did', 'you', 'go', 'into', 'the', 'pool', 'for', '?\"', 'he', 'asked'], ['\"', 'I', 'fished', 'about', 'with', 'a', 'rakehy#'], ['I', 'thought', 'there', 'might', 'be', 'some', 'weapon', 'or', 'other', 'trace'], ['But', 'how', 'on', 'earth', '--\"', '\"', 'Oh', ',', 'tut', ',', 'tut', '!', 'I', 'ahem', 'no', 'time', '!', 'That', 'left', 'foot', 'of', 'yours', 'with', 'its', 'inward', 'twist', 'is', 'all', 'over', 'the', 'place'], ['A', 'mole', 'could', 'trace', 'it', ',', 'and', 'there', 'it', 'vanishes', 'amount', 'the', 'reeds'], ['Oh', ',', 'how', 'simple', 'it', 'would', 'all', 'have', 'been', 'had', 'I', 'been', 'here', 'before', 'they', 'came', 'like', 'a', 'herd', 'of', 'buffalo', 'and', 'swallowed', 'all', 'overDxUPTDr', 'it'], ['Here', 'is', 'where', 'the', 'party', 'with', 'the', 'lodge-keeper', 'came', ',', 'and', 'they', 'have', 'covered', 'all', 'tracks', 'for', 'six', 'or', 'eight', 'feet', 'round', 'the', 'body'], ['But', 'here', 'are', 'three', 'separate', 'tracks', 'of', 'the', 'same', 'feet'], ['\"', 'He', 'drew', 'out', 'a', 'lens', 'and', 'lay', 'down', 'upon', 'his', 'waterproof', 'to', 'have', 'a', 'better', 'view', ',', 'talking', 'all', 'the', 'time', 'rather', 'to', 'himself', 'than', 'to', 'us'], ['Twice', 'he', 'was', 'walking', ',', 'and', 'once', 'he', 'ran', 'swiftly', ',', 'so', 'that', 'the', 'soles', 'are', 'deeply', 'marked', 'and', 'the', 'heels', 'hardly', 'visible'], ['That', 'bears', 'out', 'his', 'story']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results=[]\n",
        "for i in range(len(checked_rows)):\n",
        "  final_result=tokens_to_sentence(checked_rows[i])\n",
        "  final_results.append(final_result)"
      ],
      "metadata": {
        "id": "QaOmXgFjRjom"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = wer(original_sentences,final_results )\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BhvPF8HhF68",
        "outputId": "893f6c26-c2cb-4d15-adcb-f9b18b641811"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06906338694418164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_base=wer(original_sentences, replaced_sentences)\n",
        "print(error_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCz9R6lFhMoL",
        "outputId": "5a4b2cb0-cfc1-4e91-a4a0-9d799de78ff3"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07757805108798486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_pro=error/error_base\n",
        "print(error_pro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2x8VALGhZvM",
        "outputId": "27652502-d5f8-4c8d-9c49-396e73c6dc15"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8902439024390243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original: \",original_sentences[0])\n",
        "print(\"By model: \",final_results[0])\n",
        "print(\"Our corrupted version: \",replaced_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq8dD8zwhrqC",
        "outputId": "ce91ece5-f8e7-4f2a-9445-83409e59d64f"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  There was no rain, as Holmes had foretold, and the morning broke bright and cloudless\n",
            "By model:  There was no rain, as Holmes had foretold, and the morning broke bright and cloudless\n",
            "Our corrupted version:  There was no rain, as Holmes had foretold, anbd the morning broke bright anbd cloudless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#New model"
      ],
      "metadata": {
        "id": "JMP0bvf9h_rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install johnsnowlabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "75IXb-0sfM_Y",
        "outputId": "60d07101-40d2-4e39-b762-51b0025cc9ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting johnsnowlabs\n",
            "  Downloading johnsnowlabs-5.3.4-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from johnsnowlabs)\n",
            "  Downloading boto3-1.34.88-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from johnsnowlabs)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting databricks-api (from johnsnowlabs)\n",
            "  Downloading databricks_api-0.9.0-py3-none-any.whl (7.4 kB)\n",
            "Collecting dataclasses (from johnsnowlabs)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting nlu==5.3.0 (from johnsnowlabs)\n",
            "  Downloading nlu-5.3.0-py3-none-any.whl (672 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m672.9/672.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (1.25.2)\n",
            "Collecting pydantic==1.10.11 (from johnsnowlabs)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyspark==3.4.0 (from johnsnowlabs)\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from johnsnowlabs) (2.31.0)\n",
            "Collecting spark-nlp-display==5.0 (from johnsnowlabs)\n",
            "  Downloading spark_nlp_display-5.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spark-nlp==5.3.1 (from johnsnowlabs)\n",
            "  Downloading spark_nlp-5.3.1-py2.py3-none-any.whl (564 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.8/564.8 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from nlu==5.3.0->johnsnowlabs) (2.0.3)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlu==5.3.0->johnsnowlabs) (14.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.11->johnsnowlabs) (4.11.0)\n",
            "Collecting py4j==0.10.9.7 (from pyspark==3.4.0->johnsnowlabs)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from spark-nlp-display==5.0->johnsnowlabs) (7.34.0)\n",
            "Collecting svgwrite==1.4 (from spark-nlp-display==5.0->johnsnowlabs)\n",
            "  Downloading svgwrite-1.4-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.88 (from boto3->johnsnowlabs)\n",
            "  Downloading botocore-1.34.88-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->johnsnowlabs)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->johnsnowlabs)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli (from databricks-api->johnsnowlabs)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->johnsnowlabs) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.88->boto3->johnsnowlabs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu==5.3.0->johnsnowlabs) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->nlu==5.3.0->johnsnowlabs) (2024.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (8.1.7)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli->databricks-api->johnsnowlabs) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->spark-nlp-display==5.0->johnsnowlabs)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->spark-nlp-display==5.0->johnsnowlabs) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->spark-nlp-display==5.0->johnsnowlabs) (0.2.13)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317122 sha256=ab3ce5576a595848a53e9d377d6b625a7a5081667258d89a54a9a5d0f1148427\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: spark-nlp, py4j, dataclasses, svgwrite, pyspark, pydantic, jmespath, jedi, colorama, databricks-cli, botocore, spark-nlp-display, s3transfer, nlu, databricks-api, boto3, johnsnowlabs\n",
            "  Attempting uninstall: spark-nlp\n",
            "    Found existing installation: spark-nlp 5.3.3\n",
            "    Uninstalling spark-nlp-5.3.3:\n",
            "      Successfully uninstalled spark-nlp-5.3.3\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.5\n",
            "    Uninstalling py4j-0.10.9.5:\n",
            "      Successfully uninstalled py4j-0.10.9.5\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.2.3\n",
            "    Uninstalling pyspark-3.2.3:\n",
            "      Successfully uninstalled pyspark-3.2.3\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.0\n",
            "    Uninstalling pydantic-2.7.0:\n",
            "      Successfully uninstalled pydantic-2.7.0\n",
            "Successfully installed boto3-1.34.88 botocore-1.34.88 colorama-0.4.6 databricks-api-0.9.0 databricks-cli-0.18.0 dataclasses-0.6 jedi-0.19.1 jmespath-1.0.1 johnsnowlabs-5.3.4 nlu-5.3.0 py4j-0.10.9.7 pydantic-1.10.11 pyspark-3.4.0 s3transfer-0.10.1 spark-nlp-5.3.1 spark-nlp-display-5.0 svgwrite-1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "com",
                  "dataclasses",
                  "py4j",
                  "pyspark",
                  "sparknlp"
                ]
              },
              "id": "c5d80793bf1b4b329d084eec5acc6d1b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the NLP module which contains Spark NLP and NLU libraries\n",
        "from johnsnowlabs import nlp\n",
        "# Use Norvig model\n",
        "nlp.load(\"en.spell.norvig\").predict(\"Plaese alliow me tao introdduce myhelf, I am a man of wealth und tiaste\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "NELrUQiVejHc",
        "outputId": "dafc5fb2-ffda-485d-e9f4-9427c2a2c31c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "spellcheck_norvig download started this may take some time.\n",
            "Approximate size to download 4.2 MB\n",
            "[OK!]\n",
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "Warning::Spark Session already created, some configs may not take.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       spell       token\n",
              "0     Please      Plaese\n",
              "0      allow      alliow\n",
              "0         me          me\n",
              "0        tao         tao\n",
              "0  introduce  introdduce\n",
              "0     myself      myhelf\n",
              "0          ,           ,\n",
              "0          I           I\n",
              "0         am          am\n",
              "0          a           a\n",
              "0        man         man\n",
              "0         of          of\n",
              "0     wealth      wealth\n",
              "0        und         und\n",
              "0      taste      tiaste"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93766300-0366-487c-9166-d7969306efeb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spell</th>\n",
              "      <th>token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please</td>\n",
              "      <td>Plaese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allow</td>\n",
              "      <td>alliow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me</td>\n",
              "      <td>me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tao</td>\n",
              "      <td>tao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>introduce</td>\n",
              "      <td>introdduce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>myself</td>\n",
              "      <td>myhelf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>am</td>\n",
              "      <td>am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wealth</td>\n",
              "      <td>wealth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>und</td>\n",
              "      <td>und</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>taste</td>\n",
              "      <td>tiaste</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93766300-0366-487c-9166-d7969306efeb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93766300-0366-487c-9166-d7969306efeb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93766300-0366-487c-9166-d7969306efeb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3bc71877-e053-4bba-a410-84b1a7352330\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bc71877-e053-4bba-a410-84b1a7352330')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3bc71877-e053-4bba-a410-84b1a7352330 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"nlp\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"spell\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"a\",\n          \"of\",\n          \"Please\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"a\",\n          \"of\",\n          \"Plaese\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=nlp.load(\"en.spell.norvig\")\n",
        "prediction=model.predict(\"Plaese alliow me tao introdduce myhelf, I am a man of wealth und tiaste\")\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUbIOtAQf1wq",
        "outputId": "6d2974e3-ed9b-48f0-8b03-c139f6202a55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "Warning::Spark Session already created, some configs may not take.\n",
            "spellcheck_norvig download started this may take some time.\n",
            "Approximate size to download 4.2 MB\n",
            "[OK!]\n",
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "Warning::Spark Session already created, some configs may not take.\n",
            "       spell       token\n",
            "0     Please      Plaese\n",
            "0      allow      alliow\n",
            "0         me          me\n",
            "0        tao         tao\n",
            "0  introduce  introdduce\n",
            "0     myself      myhelf\n",
            "0          ,           ,\n",
            "0          I           I\n",
            "0         am          am\n",
            "0          a           a\n",
            "0        man         man\n",
            "0         of          of\n",
            "0     wealth      wealth\n",
            "0        und         und\n",
            "0      taste      tiaste\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(prediction['token'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "G2EAXjWQgFq9",
        "outputId": "38f28461-01f4-4d1c-e066-c0d6992cfbdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 244);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming prediction is your DataFrame and 'spell' is the column\n",
        "words_series = prediction['spell']\n",
        "\n",
        "# Convert Series to a list of words\n",
        "words_list = list(words_series.values)\n"
      ],
      "metadata": {
        "id": "9n51qKZ5gXEm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(prediction['spell'].values)"
      ],
      "metadata": {
        "id": "Utg0HJxAhUXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_3WPolHg6BS",
        "outputId": "df92b802-fb79-4ad2-88e2-56d3a964d075"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Please',\n",
              " 'allow',\n",
              " 'me',\n",
              " 'tao',\n",
              " 'introduce',\n",
              " 'myself',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'man',\n",
              " 'of',\n",
              " 'wealth',\n",
              " 'und',\n",
              " 'taste']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_rows=[]\n",
        "original_sentences=[]\n",
        "replaced_sentences=[]\n",
        "model=nlp.load(\"en.spell.norvig\")\n",
        "for row in df['replaced_sentence'][:50]:\n",
        "  replaced_sentences.append(row)\n",
        "  predict_rows.append(model.predict(row))\n",
        "\n",
        "for row in df['original_sentence'][:50]:\n",
        "  original_sentences.append(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rVK3M9XhkCt",
        "outputId": "e8f3479a-c842-4b9b-cd43-9576d3994969"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "Warning::Spark Session already created, some configs may not take.\n",
            "spellcheck_norvig download started this may take some time.\n",
            "Approximate size to download 4.2 MB\n",
            "[OK!]\n",
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "Warning::Spark Session already created, some configs may not take.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checked_rows=[]\n",
        "rows_tokens=[]\n",
        "for i in range(len(predict_rows)):\n",
        "  checked_rows.append(list(predict_rows[i]['spell'].values))\n",
        "\n",
        "print(checked_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b5a44d-86f7-400f-ac0b-0ed1c3efe169",
        "id": "3wEcZfnmhJA4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['There', 'was', 'no', 'rain', ',', 'as', 'Holmes', 'had', 'foretold', ',', 'inbd', 'the', 'morning', 'broke', 'bright', 'inbd', 'cloudless'], ['At', 'nine', \"'\", 'clock', 'estrade', 'called', 'for', 'us', 'with', 'the', 'carriage', ',', 'inbd', 'we', 'set', 'off', 'for', 'Hatherley', 'Farm', 'inbd', 'the', 'Boscombe', 'Pool'], ['\"', 'TherezaynKAAh', 'is', 'serious', 'news', 'this', 'morning', ',\"', 'estrade', 'observed'], ['\"', 'It', 'is', 'aid', 'taht', 'Mr'], ['Turner', ',', 'of', 'the', 'Hall', ',', 'is', 'so', 'ill', 'that', 'his', 'life', 'is', 'despaired', 'of'], ['\"', 'About', 'sixty;#', 'but', 'his', 'constitution', 'has', 'been', 'shattered', 'by', 'his', 'life', 'abroad', ',', 'anba', 'he', 'has', 'been', 'in', 'failing', 'health', 'for', 'some', 'time'], ['This', 'business', 'has', 'had', 'a', 'very', 'bad', 'effect', 'upon', 'him'], ['He', 'was', 'an', 'old', 'friend', 'of', \"McCarthy's\", ',', 'and', ',', 'I', 'may', 'add', ',', 'a', 'great', 'benefactor', 'to', 'him', ',', 'for', 'I', 'have', 'learned', 'that', 'he', 'gave', 'him', 'Hatherley', 'Farm', 'rent', 'free'], ['\"', 'Oh', ',', 'yes', '!', 'Wg', 'In', 'a', 'hundred', 'other', 'ways', 'he', 'has', 'helped', 'him'], ['Everybody', 'about', 'here', 'speaks', 'of', 'his', 'kindness', 'to', 'him'], ['\"', '\"', 'Really', '!', 'Does', 'it', 'not', 'strike', 'you', 'as', 'a', 'little', 'singular', 'that', 'this', 'McCarthy', ',', 'who', 'appears', 'to', 'have', 'had', 'little', 'of', 'his', 'own', ',', 'inbd', 'to', 'have', 'been', 'under', 'such', 'obligations', 'to', 'Turner', ',', 'should', 'still', 'talk', 'of', 'marrying', 'his', 'son', 'to', 'Turners', 'daughter', ',', 'who', 'is', ',', 'presumably', ',', 'heiress', 'to', 'the', 'estate', ',', 'inbd', 'that', 'in', 'such', 'a', 'very', 'cocksure', 'manner', ',', 'as', 'if', 'it', 'were', 'merely', 'a', 'case', 'of', 'a', 'proposal', 'anba', 'all', 'else', 'would', 'follow', '?', 'It', 'is', 'the', 'more', 'strange', ',', 'since', 'we', 'know', 'that', 'Turner', 'himself', 'was', 'averse', 'to', 'the', 'idea'], ['Do', 'you', 'not', 'deduce', 'something', 'rom', 'that', '?\"', '\"', 'We', 'have', 'got', 'to', 'the', 'deductions', 'anba', 'the', 'inferences,\"#', 'said', 'estrade', ',', 'winking', 'at', 'me'], ['\"', 'I', 'find', 'it', 'hard', 'enough', 'to', 'tackle', 'facts', ',', 'Holmes', ',', 'without', 'flying', 'away', 'after', 'theories', 'anba', 'fancies'], ['\"', '\"', 'You', 'are', 'right', ',\"', 'said', 'Holmes', 'demurely', ';', '\"', 'you', 'do', 'find', 'it', 'very', 'hard', 'to', 'tackle', 'the', 'facts'], ['\"', '\"', 'anyhow', ',', 'I', 'have', 'grasped', 'one', 'fact', 'which', 'you', 'seem', 'to', 'find', 'it', 'difficult', 'to', 'get', 'hold', 'of', ',\"', 'replied', 'estrade', 'with', 'some', 'warmth'], ['\"', 'And', 'that', 'is', '--\"', '\"', 'That', 'McCarthy', 'senior', 'met', 'his', 'death', 'from', 'McCarthy', 'junior', 'inbd', 'that', 'all', 'theories', 'to', 'the', 'contrary', 'are', 'the', 'merest', 'moonshine'], ['\"', '\"', 'Well', ',', 'moonshine', 'is', 'a', 'brighter', 'thing', 'than', 'fog', ',\"', 'said', 'Holmes', ',', 'laughing'], ['\"', 'But', 'I', 'am', 'very', 'much', 'mistaken', 'if', 'this', 'is', 'nto', 'Hatherley', 'Farm', 'upon', 'the', 'left'], ['\"', 'Yes', ',', 'taht', 'is', 'it'], ['\"', 'It', 'was', 'a', 'widespread', ',', 'comfortable-looking', 'building', ',', 'two-storied', ',', 'slate-roofed', ',', 'with', 'great', 'yellow', 'blotches', 'of', 'lichen', 'upon', 'the', 'grey', 'walls'], ['The', 'drawn', 'blinds', 'anba', 'the', 'smokeless', 'chimneys', ',', 'however', ',', 'gave', 'it', 'a', 'stricken', 'look', ',', 'as', 'though', 'the', 'weight', 'of', 'this', 'horror', 'still', 'lay', 'heavy', 'upon', 'it'], ['We', 'called', 'at', 'the', 'door', ',', 'when', 'the', 'maid', ',', 'at', 'Holmes', \"'\", 'request', ',', 'showed', 'us', 'the', 'boots', 'which', 'her', 'master', 'wore', 'at', 'the', 'time', 'of', 'his', 'death', ',', 'and', 'allot', 'a', 'pair', 'of', 'the', \"son's\", ',', 'though', 'not', 'the', 'pair', 'which', 'he', 'had', 'then', 'had'], ['Having', 'measured', 'these', 'very', 'carefully', 'from', 'seven', 'or', 'eight', 'different', 'points', ',', 'Holmes', 'desired', 'to', 'be', 'led', 'to', 'the', 'court-yard', ',', 'from', 'which', 'we', 'all', 'followed', 'the', 'winding', 'track', 'which', 'led', 'to', 'Boscombe', 'Pool'], ['Sherlocke', 'Holmes', 'was', 'transformed', 'when', 'he', 'was', 'hot', 'upon', 'such', 'a', 'scent', 'as', 'this'], ['Men', 'who', 'had', 'only', 'known', 'the', 'quiet', 'thinker', 'inbd', 'logician', 'of', 'Baker', 'Street', 'would', 'have', 'failed', 'to', 'recognise', 'him'], ['His', 'face', 'flushed', 'anba', 'darkened'], ['His', 'brows', 'were', 'drawn', 'into', 'two', 'hard', 'black', 'lines', ',', 'while', 'his', 'eyes', 'shone', 'out', 'four', 'beneath', 'them', 'with', 'a', 'steely', 'glitter'], ['His', 'face', 'was', 'bent', 'downward', ',', 'his', 'shoulders', 'bowed', ',', 'his', 'lips', 'compressed', ',', 'inbd', 'the', 'veins', 'stood', 'out', 'like', 'whipcord', 'in', 'his', 'long', ',', 'sinewy', 'neck'], ['His', 'nostrils', 'seemed', 'to', 'dilate', 'with', 'a', 'purely', 'animal', 'lust', 'for', 'the', 'chase', ',', 'inbd', 'his', 'mind', 'was', 'so', 'absolutely', 'concentrated', 'upon', 'the', 'matter', 'before', 'him', 'that', 'a', 'question', 'or', 'remark', 'fell', 'unheeded', 'upon', 'his', 'ears', ',', 'or', ',', 'at', 'the', 'most', ',', 'only', 'provoked', 'a', 'quick', ',', 'impatient', 'snarl', 'in', 'reply'], ['Swiftly', 'anba', 'silently', 'he', 'made', 'his', 'way', 'along', 'the', 'track', 'which', 'ran', 'through', 'the', 'meadowy', ',', 'anba', 'so', 'by', 'way', 'of', 'the', 'woods', 'to', 'the', 'Boscombe', 'Pool'], ['It', 'was', 'damp', ',', 'marshy', 'ground', ',', 'as', 'is', 'all', 'that', 'district', ',', 'anba', 'there', 'were', 'marks', 'of', 'many', 'feet', ',', 'both', 'upon', 'the', 'path', 'inbd', 'amid', 'the', 'short', 'grass', 'which', 'bounded', 'it', 'on', 'either', 'side'], ['Sometimes', 'holmos', 'would', 'hurry', 'on', ',', 'sometimes', 'stop', 'dead', ',', 'anba', 'once', 'he', 'made', 'quite', 'a', 'little', 'detour', 'nto', 'the', 'meadow'], ['estrade', 'anba', 'I', 'walked', 'behind', 'him', ',', 'the', 'detective', 'indifferent', 'inbd', 'contemptuous', ',', 'while', 'I', 'watched', 'my', 'friend', 'with', 'the', 'interest', 'which', 'sprang', 'from', 'the', 'conviction', 'that', 'every', 'one', 'of', 'his', 'actions', 'was', 'directed', 'towards', 'a', 'definite', 'end'], ['The', 'Boscombe', 'Pool', ',', 'which', 'is', 'a', 'little', 'reed-girt', 'sheet', 'of', 'water', 'some', 'fifty', 'yards', 'across', ',', 'is', 'situated', 'at', 'the', 'boundary', 'between', 'the', 'Hatherley', 'Farm', 'inbd', 'the', 'privates', 'park', 'of', 'the', 'wealthy', 'Mr'], ['Above', 'the', 'woods', 'which', 'lined', 'it', 'upon', 'the', 'farther', 'side', 'we', 'could', 'see', 'the', 'red', ',', 'jutting', 'pinnacles', 'which', 'marked', 'the', 'site', 'of', 'the', 'rich', \"landowner's\", 'dwelling'], ['On', 'the', 'Hatherley', 'side', 'of', 'the', 'pool', 'the', 'woods', 'grew', 'very', 'thick', ',', 'and', 'there', 'was', 'a', 'narrow', 'belt', 'of', 'sodden', 'grass', 'twenty', 'paces', 'across', 'between', 'the', 'edge', 'of', 'the', 'trees', 'and', 'the', 'reeds', 'which', 'lined', 'the', 'lake'], ['estrade', 'showed', 'us', 'the', 'exact', 'spot', 'at', 'which', 'the', 'body', 'had', 'been', 'found', ',', 'and', ',', 'indeed', ',', 'so', 'moist', 'was', 'the', 'ground', ',', 'that', 'I', 'could', 'plainly', 'see', 'the', 'traces', 'which', 'had', 'been', 'left', 'by', 'the', 'fall', 'of', 'the', 'stricken', 'man'], ['To', 'Holmes', ',', 'as', 'I', 'could', 'see', 'by', 'his', 'eager', 'face', 'anba', 'peering', 'eyes', ',', 'very', 'many', 'other', 'things', 'were', 'to', 'be', 'read', 'upon', 'the', 'trampled', 'grass'], ['He', 'ran', 'round', ',', 'like', 'a', 'dog', 'who', 'is', 'pickingbsSxa', 'up', 'a', 'scent', ',', 'inbd', 'then', 'turned', 'upon', 'my', 'companion'], ['\"\"', 'What', 'did', 'you', 'go', 'into', 'the', 'pool', 'for', '?\"', 'he', 'asked'], ['\"', 'I', 'fished', 'about', 'with', 'a', 'rakehy#'], ['I', 'thought', 'there', 'might', 'be', 'some', 'weapon', 'or', 'other', 'trace'], ['But', 'how', 'on', 'earth', '--\"', '\"', 'Oh', ',', 'tut', ',', 'tut', '!', 'I', 'ahem', 'no', 'time', '!', 'That', 'left', 'foot', 'of', 'yours', 'with', 'its', 'inward', 'twist', 'is', 'all', 'over', 'the', 'place'], ['A', 'mole', 'could', 'trace', 'it', ',', 'and', 'there', 'it', 'vanishes', 'amount', 'the', 'reeds'], ['Oh', ',', 'how', 'simple', 'it', 'would', 'all', 'have', 'been', 'had', 'I', 'been', 'here', 'before', 'they', 'came', 'like', 'a', 'herd', 'of', 'buffalo', 'inbd', 'wallowed', 'all', 'overDxUPTDr', 'it'], ['Here', 'is', 'where', 'the', 'party', 'with', 'the', 'lodge-keeper', 'came', ',', 'inbd', 'they', 'have', 'covered', 'all', 'tracks', 'for', 'six', 'or', 'eight', 'feet', 'round', 'the', 'body'], ['But', 'here', 'are', 'three', 'separate', 'tracks', 'of', 'the', 'same', 'feet'], ['\"', 'He', 'drew', 'out', 'a', 'lens', 'inbd', 'lay', 'down', 'upon', 'his', 'waterproof', 'to', 'have', 'a', 'better', 'view', ',', 'talking', 'all', 'the', 'time', 'rather', 'to', 'himself', 'than', 'to', 'us'], ['Twice', 'he', 'was', 'walking', ',', 'anba', 'once', 'he', 'ran', 'swiftly', ',', 'so', 'that', 'the', 'soles', 'are', 'deeply', 'marked', 'anba', 'the', 'heels', 'hardly', 'visible'], ['That', 'bears', 'out', 'his', 'story']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(prediction['spell'].values)"
      ],
      "metadata": {
        "id": "t_3mlsPQhbkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results=[]\n",
        "for i in range(len(checked_rows)):\n",
        "  final_result=tokens_to_sentence(checked_rows[i])\n",
        "  final_results.append(final_result)"
      ],
      "metadata": {
        "id": "p66Kc24ghJA4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = wer(original_sentences,final_results )\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8e103b-de27-46d3-e96a-282318212af0",
        "id": "Se4NlTyuhJA5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09744560075685904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_base=wer(original_sentences, replaced_sentences)\n",
        "print(error_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236d8bf1-29d7-41a7-aedb-1799ed646d69",
        "id": "zM2YAT5ChJA5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07757805108798486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_pro=error/error_base\n",
        "print(error_pro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066abc8f-a358-4fa9-bc40-8d0e680b19d4",
        "id": "knPD_8a2hJA5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2560975609756098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original: \",original_sentences[0])\n",
        "print(\"By model: \",final_results[0])\n",
        "print(\"Our corrupted version: \",replaced_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbLe2-NgkoSP",
        "outputId": "62045763-8f38-43ac-e21a-1200c1d75206"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  There was no rain, as Holmes had foretold, and the morning broke bright and cloudless\n",
            "By model:  There was no rain, as Holmes had foretold, inbd the morning broke bright inbd cloudless\n",
            "Our corrupted version:  There was no rain, as Holmes had foretold, anbd the morning broke bright anbd cloudless\n"
          ]
        }
      ]
    }
  ]
}